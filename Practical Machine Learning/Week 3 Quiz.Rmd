---
title: "Practical Machine Learning - Week 3 Quiz"
author: "Ken Wood"
date: "9/17/2020"
output: html_document
---

#### Question 1

Load the cell segmentation data from the AppliedPredictiveModeling package using the commands:
```{r}
rm(list = ls())

library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
```

1. Subset the data to a training set and testing set based on the Case variable in the data set.

```{r}

train = segmentationOriginal[segmentationOriginal$Case=="Train",]
test = segmentationOriginal[segmentationOriginal$Case=="Test",]
```

2. Set the seed to 125 and fit a CART model to predict Class with the rpart method using all predictor variables and default caret settings.

```{r}
set.seed(125)
modFit <- train(Class~.,method="rpart",data=train)
modFit$finalModel
```

```{r}
library(rattle)
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
```

3. In the final model what would be the final model prediction for cases with the following variable values:

a. TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2  
b. TotalIntench2 = 50,000; FiberWidthCh1 = 10;VarIntenCh4 = 100
c. TotalIntench2 = 57,000; FiberWidthCh1 = 8;VarIntenCh4 = 100
d. FiberWidthCh1 = 8;VarIntenCh4 = 100; PerimStatusCh1=2

Answers (determined by inspecting the tree diagram):

a. PS
b. WS
c. PS
d. Not possible to predict.

#### Question 2

If K is small in a K-fold cross validation is the bias in the estimate of out-of-sample (test set) accuracy smaller or bigger? If K is small is the variance in the estimate of out-of-sample (test set) accuracy smaller or bigger. Is K large or small in leave one out cross validation?

Answer: The bias is larger and the variance is smaller. Under leave one out cross validation K is equal to the sample size.

#### Question 3

Load the olive oil data using the commands:
```{r}
library(pgmm)
data(olive)
olive = olive[,-1]
```

These data contain information on 572 different Italian olive oils from multiple regions in Italy. Fit a classification tree where Area is the outcome variable.

```{r}

modFit1 <- train(Area~.,method="rpart",data=olive)
modFit1$finalModel
```
```{r}
fancyRpartPlot(modFit1$finalModel)
```

```{r}
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit1,newdata = newdata)
```
The predicted value is 2.783. It is strange because Area should be a qualitative variable - but tree is reporting the average value of Area as a numeric variable in the leaf predicted for newdata.

#### Question 4

Load the South Africa Heart Disease Data and create training and test sets with the following code:

```{r}
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
```

Set the seed to 13234 and fit a logistic regression model (method="glm", be sure to specify family="binomial") with Coronary Heart Disease (chd) as the outcome and age at onset, current alcohol consumption, obesity levels, cumulative tabacco, type-A behavior, and low density lipoprotein cholesterol as predictors. 

```{r}
set.seed(13234)
modFit2 <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
```

```{r}
summary(modFit2)
```
Calculate the misclassification rate for your model using this function and a prediction on the "response" scale:
```{r}
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}

# Calculate misclassification rate on 'trainSA' dataset
missClass(trainSA$chd,predict(modFit2, newdata = trainSA))
```

```{r}
# Calculate misclassification rate on 'testSA' dataset
missClass(testSA$chd,predict(modFit2, newdata = testSA))
```

#### Question 5

Load the vowel.train and vowel.test data sets:
```{r}
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
```
Set the variable y to be a factor variable in both the training and test set. Then set the seed to 33833. Fit a random forest predictor relating the factor variable y to the remaining variables. Read about variable importance in random forests here: http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#ooberr The caret package uses the Gini importance be default. Calculate the variable importance using the varImp function in the caret package. What is the order of variable importance?
```{r}
set.seed(33833)
library(randomForest)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)

modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = TRUE)
```
